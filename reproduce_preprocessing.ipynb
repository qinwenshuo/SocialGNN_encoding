{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T21:17:08.669700Z",
     "start_time": "2024-09-03T21:17:08.556558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T21:17:14.117880Z",
     "start_time": "2024-09-03T21:17:08.671505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import pynvml\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Check if TensorFlow is using the GPU\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"TensorFlow is using the GPU\")\n",
    "    \n",
    "    # Initialize the pynvml library\n",
    "    pynvml.nvmlInit()\n",
    "    \n",
    "    # Get the number of GPU devices\n",
    "    num_gpus = pynvml.nvmlDeviceGetCount()\n",
    "    \n",
    "    # Iterate over GPU devices\n",
    "    for i in range(num_gpus):\n",
    "        # Get the device identifier\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "        # Get the full GPU name\n",
    "        gpu_name = pynvml.nvmlDeviceGetName(handle)\n",
    "        print(\"GPU Name:\", gpu_name)\n",
    "        \n",
    "    # Shutdown the pynvml library\n",
    "    pynvml.nvmlShutdown()\n",
    "else:\n",
    "    print(\"TensorFlow is not using the GPU\")"
   ],
   "id": "a45c005b532337af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is using the GPU\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T21:17:14.133387Z",
     "start_time": "2024-09-03T21:17:14.118957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "video_path = 'GAZE_dataset/video'\n",
    "original_annotation_path = 'GAZE_dataset/annotation_cleaned/'\n",
    "my_annotation_path = 'GAZE_dataset/annotations.csv'\n",
    "patches_path = 'GAZE_dataset/preprocess/video_data/'\n",
    "pca_dir = \"GAZE_dataset/preprocess/fitted_PCA\""
   ],
   "id": "4ffc38c2ecdb6546",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T21:17:14.148539Z",
     "start_time": "2024-09-03T21:17:14.135387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        pickled = pickle.load(f)\n",
    "    return pickled\n",
    "\n",
    "def save_pickle(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f)"
   ],
   "id": "d14224fd38a0145d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Face annotations\n",
    "\n",
    "loop each author annotations to creat my annotations"
   ],
   "id": "7f6fca3e9dd03444"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bounding_box_data = []\n",
    "\n",
    "for i in range(1, 302):\n",
    "    each_annotation = f'NewAnt_{i}.txt'\n",
    "    annotation_path = os.path.join(original_annotation_path, each_annotation)\n",
    "    video_name = f'{i}.mp4'\n",
    "    try:\n",
    "        with open(annotation_path, 'r') as f:\n",
    "            file_lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f'File {annotation_path} not found, the annotation is lost')\n",
    "        continue\n",
    "    for line in file_lines:\n",
    "        if line.strip():\n",
    "            data = line.strip().split(' ')\n",
    "            label = data[9]\n",
    "            if len(data) == 10:\n",
    "                gaze_direction = None\n",
    "                event_attribute = None\n",
    "                atomic_attribute = None\n",
    "            elif len(data) == 13:\n",
    "                gaze_direction = data[-1]\n",
    "                if gaze_direction == 'P1': gaze_direction = f'{label}, Person1'\n",
    "                elif gaze_direction == 'P2': gaze_direction = f'{label}, Person2'\n",
    "                elif gaze_direction == 'P3': gaze_direction = f'{label}, Person3'\n",
    "                elif gaze_direction == 'P4': gaze_direction = f'{label}, Person4'\n",
    "                elif gaze_direction == 'O1': gaze_direction = f'{label}, Object1'\n",
    "                elif gaze_direction == 'O2': gaze_direction = f'{label}, Object2'\n",
    "                elif gaze_direction == 'O3': gaze_direction = f'{label}, Object3'\n",
    "                elif gaze_direction == 'O4': gaze_direction = f'{label}, Object4'\n",
    "                elif gaze_direction == 'O5': gaze_direction = f'{label}, Object5'\n",
    "                elif gaze_direction == 'NA': gaze_direction = None\n",
    "                event_attribute = data[10]\n",
    "                atomic_attribute = data[11]\n",
    "                \n",
    "            frame_data = {'video_name': video_name,\n",
    "                          'frame': int(data[5])+1,\n",
    "                          'label_name': data[9],\n",
    "                          'left': int(data[1]),\n",
    "                          'top' : int(data[2]),\n",
    "                          'right': int(data[3]),\n",
    "                          'bottom': int(data[4]),\n",
    "                          'gaze_direction': gaze_direction,\n",
    "                          'event_attribute': event_attribute,\n",
    "                          'atomic_attribute': atomic_attribute,\n",
    "                          }\n",
    "            bounding_box_data.append(frame_data)"
   ],
   "id": "41720809e12e39bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "annotations = pd.DataFrame(bounding_box_data)\n",
    "annotations"
   ],
   "id": "cdb03c90ac48f499",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "annotations.to_csv(my_annotation_path, index=False)",
   "id": "427879afbea1068b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CROP OUT IMAGES PATCHES FROM VIDEOS\n",
   "id": "faa13c7ea0fa06b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "annotations = pd.read_csv(my_annotation_path)\n",
    "annotations"
   ],
   "id": "1b44c7c8ed295e4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Iterate over each unique video in the DataFrame\n",
    "for video_name in tqdm(annotations['video_name'].unique()):\n",
    "    # print(\"Processing video:\", video_name)\n",
    "    # Fetch all frames annotations in this video\n",
    "    save_path = os.path.join(patches_path, video_name)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    video = cv2.VideoCapture(os.path.join(video_path, video_name))\n",
    "    video_annotations = annotations[annotations['video_name'] == video_name]\n",
    "    patches = []\n",
    "    annotations_dict = {'labels': [], 'frame_numbers': [], \n",
    "                        'left': [], 'right': [], 'top': [], 'bottom': [],\n",
    "                        'gaze_direction': [], 'event_attribute': [], 'atomic_attribute': []}\n",
    "    \n",
    "    for current_frame in range(1, video_annotations['frame'].iloc[-1]+1):  # in the range of number of frames\n",
    "        successful_read, frame = video.read()\n",
    "        if successful_read:\n",
    "            # Filter annotations for the current frame\n",
    "            frame_annotations = video_annotations[video_annotations['frame'] == current_frame]\n",
    "            if not frame_annotations.empty:\n",
    "                for _, entity in frame_annotations.iterrows():\n",
    "                    patches.append(frame[int(entity['top']):int(entity['bottom']),int(entity['left']):int(entity['right'])])\n",
    "                    annotations_dict['labels'].append(entity['label_name'])\n",
    "                    annotations_dict['frame_numbers'].append(current_frame)\n",
    "                    annotations_dict['left'].append(int(entity['left']))\n",
    "                    annotations_dict['right'].append(int(entity['right']))\n",
    "                    annotations_dict['top'].append(int(entity['top']))\n",
    "                    annotations_dict['bottom'].append(int(entity['bottom']))\n",
    "                    annotations_dict['gaze_direction'].append(entity['gaze_direction'])\n",
    "                    annotations_dict['event_attribute'].append(entity['event_attribute'])\n",
    "                    annotations_dict['atomic_attribute'].append(entity['atomic_attribute'])\n",
    "                    \n",
    "        else:\n",
    "            raise ValueError(f\"Unsuccessful read frame {current_frame} of {video_name}\")\n",
    "    save_pickle(patches, os.path.join(save_path, 'patches'))\n",
    "    annotation_df = pd.DataFrame(annotations_dict)\n",
    "    save_pickle(annotation_df, os.path.join(save_path, 'annotations'))\n"
   ],
   "id": "35e6f1cb3642d7bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " def visualize_patches(num_patches_to_display=10):\n",
    "    # Get a list of all subdirectories in the patches_output_path directory\n",
    "    videos = [d for d in os.listdir(patches_path)]\n",
    "    import random\n",
    "    # Randomly select one of the subdirectories\n",
    "    selected_subdir = random.choice(videos)\n",
    "    selected_path = os.path.join(patches_path, selected_subdir)\n",
    "    \n",
    "    patches = load_pickle(os.path.join(selected_path, 'patches'))\n",
    "    annot = load_pickle(os.path.join(selected_path, 'annotations'))\n",
    "    \n",
    "    # Display each patch with its corresponding labels\n",
    "    print(len(patches))\n",
    "    for i, patch in enumerate(patches):\n",
    "        print(annot.loc[i, 'frame_numbers'])\n",
    "        print(annot.loc[i, 'labels'])\n",
    "        print(annot.loc[i, 'gaze_direction'])\n",
    "        plt.imshow(cv2.cvtColor(patch, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        if i+2> num_patches_to_display:\n",
    "            break\n"
   ],
   "id": "8a9e019c0a34fe97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_patches(5)",
   "id": "e7abcecc8a759b74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## VGG FEATURES",
   "id": "c4107393b9f5de3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import smart_resize\n",
    "from tensorflow.keras.models import Model"
   ],
   "id": "4250f26d27887b03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def reshape_patches(x):\n",
    "    temp = np.expand_dims(x, axis=0)\n",
    "    temp2 = preprocess_input(smart_resize(temp, (224,224)))\n",
    "    return temp2[0]"
   ],
   "id": "d97c96001ee8d75d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)"
   ],
   "id": "e229246bc623ece8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "restart = input('Do you want to reparse the input videos? (y/n)')",
   "id": "b5306c00d6202bdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 32  # Adjust this batch size based on your memory capacity\n",
    "\n",
    "for video in tqdm(os.listdir(patches_path)):\n",
    "    video_dir = os.path.join(patches_path, video)\n",
    "    patch_dir = os.path.join(video_dir, \"patches\")\n",
    "    out_dir = os.path.join(video_dir, \"VGG19_patches\")\n",
    "    if not os.path.exists(out_dir) or restart == 'y':\n",
    "        patches = load_pickle(patch_dir)\n",
    "        y_total = []\n",
    "        \n",
    "        for i in range(0, len(patches), batch_size):\n",
    "            batch_patches = patches[i:i + batch_size]\n",
    "            x_batch = [reshape_patches(patch) for patch in batch_patches]\n",
    "            x_batch = np.array(x_batch)\n",
    "            y_batch = model.predict(x_batch, verbose=0)\n",
    "            y_total.extend(y_batch)\n",
    "        \n",
    "        y_total = np.array(y_total)\n",
    "        save_pickle(y_total, out_dir)\n",
    "        print(f\"VGG19 patches saved to {video_dir}\")\n"
   ],
   "id": "d22d20d67adbdfe6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "324ac20b8cbe2cc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fit PCA",
   "id": "53b6fbefae196191"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "id": "1f687660168dae0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_all_vggfeatures():\n",
    "    all_features = []\n",
    "    for video in tqdm(os.listdir(patches_path)):\n",
    "        patch_dir = os.path.join(patches_path, video, \"VGG19_patches\")\n",
    "        all_features.extend(load_pickle(patch_dir))\n",
    "\n",
    "    all_features = np.array(all_features)\n",
    "    print(all_features.shape)\n",
    "    return all_features\n",
    "\n",
    "\n",
    "def fit_pca(all_features):\n",
    "    pca = PCA(n_components=20)\n",
    "    scaler = StandardScaler()\n",
    "    all_features_scaled = scaler.fit_transform(all_features)\n",
    "    pca.fit(all_features_scaled)\n",
    "    return pca, scaler"
   ],
   "id": "be6708392c21fa97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pca, scaler = fit_pca(extract_all_vggfeatures())",
   "id": "bb02d471c3f7ac3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_pickle(pca, os.path.join(pca_dir, \"pca\"))\n",
    "save_pickle(scaler, os.path.join(pca_dir, \"scaler\"))"
   ],
   "id": "6a5170e5f76866ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PCA on VGG features",
   "id": "9549c5f8d82c126f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pca = load_pickle(os.path.join(pca_dir, \"pca\"))\n",
    "scaler = load_pickle(os.path.join(pca_dir, 'scaler'))"
   ],
   "id": "8af163c062d01c8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for video in tqdm(os.listdir(patches_path)):\n",
    "    video_dir = os.path.join(patches_path, video)\n",
    "    patch_dir = os.path.join(video_dir, \"VGG19_patches\")\n",
    "    vgg_features = load_pickle(patch_dir)\n",
    "    scaled_features = scaler.transform(vgg_features)\n",
    "    pca_features = pca.transform(scaled_features)\n",
    "    save_pickle(pca_features, os.path.join(video_dir, \"pca_features\"))   "
   ],
   "id": "cafbf53d112df457",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Node Features\n",
   "id": "f83d5c32898610c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T21:17:28.777372Z",
     "start_time": "2024-09-03T21:17:14.150540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for video in tqdm(os.listdir(patches_path)):\n",
    "    video_dir = os.path.join(patches_path, video)\n",
    "    pca_features = load_pickle(os.path.join(video_dir, \"pca_features\"))\n",
    "    video_annot = load_pickle(os.path.join(video_dir, \"annotations\"))\n",
    "    new_features = []\n",
    "    for i, patch_feature in enumerate(pca_features):\n",
    "        new_feature = np.append(patch_feature, [video_annot['top'][i], video_annot['bottom'][i], video_annot['left'][i], video_annot['right'][i]])\n",
    "        new_feature = np.append(new_feature, [0] if 'Person' in video_annot['labels'][i] else [1])\n",
    "        assert len(new_feature) == 25\n",
    "        new_features.append(new_feature)\n",
    "    video_annot['features'] = new_features\n",
    "    save_pickle(video_annot, os.path.join(video_dir, \"annotations\"))"
   ],
   "id": "6c92a99d2e2d0b5c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:14<00:00, 20.47it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T21:17:28.824287Z",
     "start_time": "2024-09-03T21:17:28.788488Z"
    }
   },
   "cell_type": "code",
   "source": "video_annot",
   "id": "a52731bcca7f31a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      labels  frame_numbers  left  right  top  bottom    gaze_direction  \\\n",
       "0    Person1              1   113    216   51     164  Person1, Person2   \n",
       "1    Person2              1   282    397  138     257               NaN   \n",
       "2    Person3              1   442    548   82     203  Person3, Person2   \n",
       "3    Person1              2   112    215   49     162  Person1, Person2   \n",
       "4    Person2              2   284    399  138     257               NaN   \n",
       "..       ...            ...   ...    ...  ...     ...               ...   \n",
       "429  Person3            159   445    604   30     218  Person3, Person2   \n",
       "430  Person2            160   100    280   25     243               NaN   \n",
       "431  Person3            160   444    603   29     217  Person3, Person2   \n",
       "432  Person2            161   102    282   25     243               NaN   \n",
       "433  Person3            161   443    602   28     216  Person3, Person2   \n",
       "\n",
       "    event_attribute atomic_attribute  \\\n",
       "0          JointAtt            share   \n",
       "1        SingleGaze           single   \n",
       "2          JointAtt            share   \n",
       "3          JointAtt            share   \n",
       "4        SingleGaze           single   \n",
       "..              ...              ...   \n",
       "429      SingleGaze           single   \n",
       "430      SingleGaze           single   \n",
       "431      SingleGaze           single   \n",
       "432      SingleGaze           single   \n",
       "433      SingleGaze           single   \n",
       "\n",
       "                                              features  \n",
       "0    [8.036102294921875, 4.258021354675293, -11.081...  \n",
       "1    [7.617413520812988, -3.1622202396392822, -10.4...  \n",
       "2    [6.087184429168701, -1.9500582218170166, -16.0...  \n",
       "3    [8.91508960723877, 5.341881275177002, -12.9686...  \n",
       "4    [7.9217023849487305, -5.645524978637695, -10.4...  \n",
       "..                                                 ...  \n",
       "429  [14.547962188720703, 5.710830211639404, -18.56...  \n",
       "430  [16.786794662475586, 8.768088340759277, -10.03...  \n",
       "431  [13.938580513000488, 5.046601295471191, -17.98...  \n",
       "432  [17.398128509521484, 6.241418838500977, -11.29...  \n",
       "433  [14.273844718933105, 3.9898736476898193, -17.7...  \n",
       "\n",
       "[434 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>frame_numbers</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>top</th>\n",
       "      <th>bottom</th>\n",
       "      <th>gaze_direction</th>\n",
       "      <th>event_attribute</th>\n",
       "      <th>atomic_attribute</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person1</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>216</td>\n",
       "      <td>51</td>\n",
       "      <td>164</td>\n",
       "      <td>Person1, Person2</td>\n",
       "      <td>JointAtt</td>\n",
       "      <td>share</td>\n",
       "      <td>[8.036102294921875, 4.258021354675293, -11.081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Person2</td>\n",
       "      <td>1</td>\n",
       "      <td>282</td>\n",
       "      <td>397</td>\n",
       "      <td>138</td>\n",
       "      <td>257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SingleGaze</td>\n",
       "      <td>single</td>\n",
       "      <td>[7.617413520812988, -3.1622202396392822, -10.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Person3</td>\n",
       "      <td>1</td>\n",
       "      <td>442</td>\n",
       "      <td>548</td>\n",
       "      <td>82</td>\n",
       "      <td>203</td>\n",
       "      <td>Person3, Person2</td>\n",
       "      <td>JointAtt</td>\n",
       "      <td>share</td>\n",
       "      <td>[6.087184429168701, -1.9500582218170166, -16.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Person1</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>215</td>\n",
       "      <td>49</td>\n",
       "      <td>162</td>\n",
       "      <td>Person1, Person2</td>\n",
       "      <td>JointAtt</td>\n",
       "      <td>share</td>\n",
       "      <td>[8.91508960723877, 5.341881275177002, -12.9686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Person2</td>\n",
       "      <td>2</td>\n",
       "      <td>284</td>\n",
       "      <td>399</td>\n",
       "      <td>138</td>\n",
       "      <td>257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SingleGaze</td>\n",
       "      <td>single</td>\n",
       "      <td>[7.9217023849487305, -5.645524978637695, -10.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Person3</td>\n",
       "      <td>159</td>\n",
       "      <td>445</td>\n",
       "      <td>604</td>\n",
       "      <td>30</td>\n",
       "      <td>218</td>\n",
       "      <td>Person3, Person2</td>\n",
       "      <td>SingleGaze</td>\n",
       "      <td>single</td>\n",
       "      <td>[14.547962188720703, 5.710830211639404, -18.56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Person2</td>\n",
       "      <td>160</td>\n",
       "      <td>100</td>\n",
       "      <td>280</td>\n",
       "      <td>25</td>\n",
       "      <td>243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SingleGaze</td>\n",
       "      <td>single</td>\n",
       "      <td>[16.786794662475586, 8.768088340759277, -10.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Person3</td>\n",
       "      <td>160</td>\n",
       "      <td>444</td>\n",
       "      <td>603</td>\n",
       "      <td>29</td>\n",
       "      <td>217</td>\n",
       "      <td>Person3, Person2</td>\n",
       "      <td>SingleGaze</td>\n",
       "      <td>single</td>\n",
       "      <td>[13.938580513000488, 5.046601295471191, -17.98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>Person2</td>\n",
       "      <td>161</td>\n",
       "      <td>102</td>\n",
       "      <td>282</td>\n",
       "      <td>25</td>\n",
       "      <td>243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SingleGaze</td>\n",
       "      <td>single</td>\n",
       "      <td>[17.398128509521484, 6.241418838500977, -11.29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>Person3</td>\n",
       "      <td>161</td>\n",
       "      <td>443</td>\n",
       "      <td>602</td>\n",
       "      <td>28</td>\n",
       "      <td>216</td>\n",
       "      <td>Person3, Person2</td>\n",
       "      <td>SingleGaze</td>\n",
       "      <td>single</td>\n",
       "      <td>[14.273844718933105, 3.9898736476898193, -17.7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split into Sequences",
   "id": "93a0ca61ce418fef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T21:17:28.840306Z",
     "start_time": "2024-09-03T21:17:28.826286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_sequences(dir, df):\n",
    "    splits = []\n",
    "    labels = []\n",
    "    start_index = 0\n",
    "    \n",
    "    # Get the unique frame numbers\n",
    "    unique_frames = df['frame_numbers'].unique()\n",
    "    \n",
    "    # Create a list of (label, event_attribute) pairs for the first frame, handling NaNs\n",
    "    previous_pairs = list(df[df['frame_numbers'] == unique_frames[0]][['labels', 'event_attribute']].map(lambda x: None if pd.isna(x) else x).itertuples(index=False, name=None))\n",
    "    labels.append(previous_pairs)\n",
    "    \n",
    "    for i in range(1, len(unique_frames)):\n",
    "        frame = unique_frames[i]\n",
    "        # Create a list of (label, event_attribute) pairs for the current frame, handling NaNs\n",
    "        current_pairs = list(df[df['frame_numbers'] == frame][['labels', 'event_attribute']].map(lambda x: None if pd.isna(x) else x).itertuples(index=False, name=None))\n",
    "        \n",
    "        # Check if there's any difference in pairs\n",
    "        if current_pairs != previous_pairs:\n",
    "            # If there's a change, store the DataFrame slice\n",
    "            splits.append(df[df['frame_numbers'].isin(unique_frames[start_index:i])])\n",
    "            # Update the start_index for the next split\n",
    "            start_index = i\n",
    "            labels.append(current_pairs)\n",
    "        \n",
    "        # Update the previous pairs\n",
    "        previous_pairs = current_pairs\n",
    "    \n",
    "    \n",
    "    # Append the last segment\n",
    "    splits.append(df[df['frame_numbers'].isin(unique_frames[start_index:])])\n",
    "    # Save all the sequences\n",
    "    for i, split in enumerate(splits):\n",
    "        save_pickle(split, os.path.join(dir, f\"sequence_{i}\"))\n",
    "    for i, label in enumerate(labels):\n",
    "        save_pickle(label, os.path.join(dir, f\"label_{i}\"))"
   ],
   "id": "ff9dbdd22742688c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T21:18:55.462546Z",
     "start_time": "2024-09-03T21:17:41.851976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for video in tqdm(os.listdir(patches_path)):\n",
    "    video_dir = os.path.join(patches_path, video)\n",
    "    video_annot = load_pickle(os.path.join(video_dir, \"annotations\"))\n",
    "    split_sequences(video_dir, video_annot)"
   ],
   "id": "35565641c30914a9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [01:13<00:00,  4.06it/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparing preprocessed results",
   "id": "d863d73ed5b2fc15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T21:18:55.493538Z",
     "start_time": "2024-09-03T21:18:55.473515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = load_pickle('GAZE_dataset/preprocess/video_data/1.mp4/sequence_0')\n",
    "test_label = load_pickle('GAZE_dataset/preprocess/video_data/1.mp4/label_0')"
   ],
   "id": "fd878a9326b142a3",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T21:18:55.525419Z",
     "start_time": "2024-09-03T21:18:55.496350Z"
    }
   },
   "cell_type": "code",
   "source": "test",
   "id": "ac91ec8b063d33e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       labels  frame_numbers  left  right  top  bottom    gaze_direction  \\\n",
       "0     Object1              1   222    281  221     329               NaN   \n",
       "1     Person1              1   104    219   54     225  Person1, Object1   \n",
       "2     Person2              1   402    533   46     213  Person2, Object1   \n",
       "3     Object1              2   222    281  220     328               NaN   \n",
       "4     Person1              2   104    219   53     224  Person1, Object1   \n",
       "...       ...            ...   ...    ...  ...     ...               ...   \n",
       "1162  Person1            388   117    232   50     221  Person1, Person2   \n",
       "1163  Person2            388   405    536   44     211  Person2, Object1   \n",
       "1164  Object1            389   250    309  201     309               NaN   \n",
       "1165  Person1            389   117    232   50     221  Person1, Person2   \n",
       "1166  Person2            389   405    536   44     211  Person2, Object1   \n",
       "\n",
       "     event_attribute atomic_attribute  \\\n",
       "0                NaN              NaN   \n",
       "1           JointAtt            share   \n",
       "2           JointAtt            share   \n",
       "3                NaN              NaN   \n",
       "4           JointAtt            share   \n",
       "...              ...              ...   \n",
       "1162        JointAtt           single   \n",
       "1163        JointAtt           follow   \n",
       "1164             NaN              NaN   \n",
       "1165        JointAtt           single   \n",
       "1166        JointAtt           follow   \n",
       "\n",
       "                                               features  \n",
       "0     [-19.127185821533203, 1.0257439613342285, 8.13...  \n",
       "1     [10.227248191833496, 7.964693069458008, 12.540...  \n",
       "2     [12.812596321105957, 16.57403564453125, 5.0224...  \n",
       "3     [-18.33278465270996, 0.13410010933876038, 7.71...  \n",
       "4     [9.586922645568848, 8.327394485473633, 12.9994...  \n",
       "...                                                 ...  \n",
       "1162  [1.0717928409576416, 3.1524481773376465, 13.95...  \n",
       "1163  [11.605825424194336, 16.11509132385254, 4.5107...  \n",
       "1164  [-15.997661590576172, 11.390559196472168, 4.43...  \n",
       "1165  [1.7502381801605225, 3.183852434158325, 14.225...  \n",
       "1166  [11.670022010803223, 16.32166290283203, 4.5290...  \n",
       "\n",
       "[1167 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>frame_numbers</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>top</th>\n",
       "      <th>bottom</th>\n",
       "      <th>gaze_direction</th>\n",
       "      <th>event_attribute</th>\n",
       "      <th>atomic_attribute</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Object1</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>281</td>\n",
       "      <td>221</td>\n",
       "      <td>329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-19.127185821533203, 1.0257439613342285, 8.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Person1</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>219</td>\n",
       "      <td>54</td>\n",
       "      <td>225</td>\n",
       "      <td>Person1, Object1</td>\n",
       "      <td>JointAtt</td>\n",
       "      <td>share</td>\n",
       "      <td>[10.227248191833496, 7.964693069458008, 12.540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Person2</td>\n",
       "      <td>1</td>\n",
       "      <td>402</td>\n",
       "      <td>533</td>\n",
       "      <td>46</td>\n",
       "      <td>213</td>\n",
       "      <td>Person2, Object1</td>\n",
       "      <td>JointAtt</td>\n",
       "      <td>share</td>\n",
       "      <td>[12.812596321105957, 16.57403564453125, 5.0224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Object1</td>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "      <td>281</td>\n",
       "      <td>220</td>\n",
       "      <td>328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-18.33278465270996, 0.13410010933876038, 7.71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Person1</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>219</td>\n",
       "      <td>53</td>\n",
       "      <td>224</td>\n",
       "      <td>Person1, Object1</td>\n",
       "      <td>JointAtt</td>\n",
       "      <td>share</td>\n",
       "      <td>[9.586922645568848, 8.327394485473633, 12.9994...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>Person1</td>\n",
       "      <td>388</td>\n",
       "      <td>117</td>\n",
       "      <td>232</td>\n",
       "      <td>50</td>\n",
       "      <td>221</td>\n",
       "      <td>Person1, Person2</td>\n",
       "      <td>JointAtt</td>\n",
       "      <td>single</td>\n",
       "      <td>[1.0717928409576416, 3.1524481773376465, 13.95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>Person2</td>\n",
       "      <td>388</td>\n",
       "      <td>405</td>\n",
       "      <td>536</td>\n",
       "      <td>44</td>\n",
       "      <td>211</td>\n",
       "      <td>Person2, Object1</td>\n",
       "      <td>JointAtt</td>\n",
       "      <td>follow</td>\n",
       "      <td>[11.605825424194336, 16.11509132385254, 4.5107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>Object1</td>\n",
       "      <td>389</td>\n",
       "      <td>250</td>\n",
       "      <td>309</td>\n",
       "      <td>201</td>\n",
       "      <td>309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-15.997661590576172, 11.390559196472168, 4.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>Person1</td>\n",
       "      <td>389</td>\n",
       "      <td>117</td>\n",
       "      <td>232</td>\n",
       "      <td>50</td>\n",
       "      <td>221</td>\n",
       "      <td>Person1, Person2</td>\n",
       "      <td>JointAtt</td>\n",
       "      <td>single</td>\n",
       "      <td>[1.7502381801605225, 3.183852434158325, 14.225...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>Person2</td>\n",
       "      <td>389</td>\n",
       "      <td>405</td>\n",
       "      <td>536</td>\n",
       "      <td>44</td>\n",
       "      <td>211</td>\n",
       "      <td>Person2, Object1</td>\n",
       "      <td>JointAtt</td>\n",
       "      <td>follow</td>\n",
       "      <td>[11.670022010803223, 16.32166290283203, 4.5290...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1167 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5ca9c6acef503cfb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "281， 222， 329， 221\n",
    "rig, left, bot, top\n",
    "top, bot, lef, rig"
   ],
   "id": "d2445e8e007377ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:24:57.470196Z",
     "start_time": "2024-09-03T20:24:57.450195Z"
    }
   },
   "cell_type": "code",
   "source": "test_label",
   "id": "fa12d4278fc8037",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Object1', None), ('Person1', 'JointAtt'), ('Person2', 'JointAtt')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "manasi_test = load_pickle('GAZE_dataset/Manasi_preprocessed_pickles/processed_Mar25_0')",
   "id": "8b1cf4fecebde1b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:44:34.747819Z",
     "start_time": "2024-09-03T20:44:34.739631Z"
    }
   },
   "cell_type": "code",
   "source": "manasi_test['1']['sequences'][0][0][0]",
   "id": "7e8d0c6a62c748db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([19.127209432632547, -1.0256831867282694, 8.13335232314885, -4.201163709443032, 1.8991420331250286, -13.876740169041135, -5.526908531131593, -3.8356414133755274, 9.519650781813894, -3.851486033541, -10.705018150235949, -5.2528136370278915, -1.2222795299178517, 2.5200896122278476, -1.901773983292112, -0.8833180093497349, -0.5375356957939621, -4.3363662521959885, 3.3842700418425578, -3.2342044946744766, 221, 329, 222, 281]),\n",
       "       list([-10.227210662910501, -7.964693699370105, 12.540352411872792, -11.681789480086213, 0.30675131708999126, -10.135767468020056, -5.339033053269009, -1.821363372032125, 5.746255099644273, -0.02389578031439287, -6.916765072423783, 8.810839903650729, 1.9119219721072658, 3.520538773271611, 6.203606830129152, 7.181162217732476, -3.5985563941815815, -0.4146291782533541, 6.5097611640900555, 1.183150324798416, 54, 225, 104, 219]),\n",
       "       list([-12.812543674851636, -16.574032737620364, 5.022561399135988, -1.9710347021824894, -4.590026455200244, -14.132404203224567, 3.5610422346674504, -2.152768956237242, 9.752300526531194, -5.934178701440138, 7.906169869012861, -4.110902741132687, 2.4604946333069417, 5.639692802635624, 4.779487860544534, 1.6455319386440521, -3.6249220467071455, -0.9593423312896159, 0.4130565702495333, -1.7666946038529956, 46, 213, 402, 533])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build Graph\n",
   "id": "571be050246999b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T19:49:53.512223Z",
     "start_time": "2024-09-03T19:46:39.292380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_videos = []\n",
    "all_labels = ['Person1', 'Person2', 'Person3', 'Person4', 'Object1', 'Object2', 'Object3', 'Object4', 'Object5']\n",
    "for video_name in tqdm(sorted(os.listdir(patches_path))):\n",
    "    video_dir = os.path.join(patches_path, video_name)\n",
    "    for pickle_name in os.listdir(video_dir):\n",
    "        if 'sequence' in pickle_name:\n",
    "            annotations = load_pickle(os.path.join(video_dir, pickle_name))\n",
    "            labels = annotations[annotations['frame_numbers'] == annotations['frame_numbers'].iloc[0]][['labels', 'event_attribute']].map(lambda x: None if pd.isna(x) else x)\n",
    "            # Transform the data into the desired format\n",
    "            labels = [{k: v for k, v in zip(labels['labels'], labels['event_attribute'])}]\n",
    "            video_dict = {'labels':labels, 'graph_dicts':[], 'video_name': f'{video_name}_{pickle_name}'} \n",
    "            grouped = annotations.groupby('frame_numbers')\n",
    "\n",
    "            for frame_number, group in grouped:\n",
    "                edges = group['gaze_direction']\n",
    "                senders = []\n",
    "                receivers = []\n",
    "                nodes = []\n",
    "                # Process in the order of the all_labels list\n",
    "                for i, entity in enumerate(all_labels):                \n",
    "                    # if the entity exists\n",
    "                    if (annotations['labels'] == entity).any():\n",
    "                        # Access the value in the 'features' and 'gazes' columns of that entity\n",
    "                        feature = annotations.loc[annotations['labels'] == entity, 'features'].iloc[0]\n",
    "                        nodes.append(feature.tolist())\n",
    "                        edge = annotations.loc[annotations['labels'] == entity, 'gaze_direction'].iloc[0]\n",
    "                        # if gaze exists (only when the entity is person)\n",
    "                        if not isinstance(edge, float):\n",
    "                            sender, receiver = edge.split(', ')\n",
    "                            # if the gaze is at some entities not found in the video, the gaze will be discarded\n",
    "                            if sender == entity and receiver != \"neither\" and receiver in all_labels: \n",
    "                                senders.append(i)\n",
    "                                receivers.append(all_labels.index(receiver))\n",
    "                    # else:\n",
    "                    #     # Pad the nodes if there are missing feature/less than 5 features\n",
    "                    #     nodes.append([0 for j in range(25)])\n",
    "\n",
    "                # assert len(nodes) == 5\n",
    "\n",
    "                graph_dict = {'nodes': nodes, 'senders': senders, 'receivers': receivers}\n",
    "                video_dict['graph_dicts'].append(graph_dict)\n",
    "            \n",
    "    all_videos.append(video_dict)"
   ],
   "id": "f6eff4d74838c831",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [03:14<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T19:53:22.730653Z",
     "start_time": "2024-09-03T19:53:22.529584Z"
    }
   },
   "cell_type": "code",
   "source": "save_pickle(all_videos, \"GAZE_dataset/preprocess/graphs\")",
   "id": "952c4904ace897b2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T19:53:34.400378Z",
     "start_time": "2024-09-03T19:53:34.353442Z"
    }
   },
   "cell_type": "code",
   "source": "all_videos",
   "id": "956d04ebf9b3cf99",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mall_videos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
