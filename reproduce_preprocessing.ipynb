{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T17:16:43.975429Z",
     "start_time": "2024-09-13T17:16:43.944279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T17:16:50.566878Z",
     "start_time": "2024-09-13T17:16:44.227011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import pynvml\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Check if TensorFlow is using the GPU\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"TensorFlow is using the GPU\")\n",
    "    \n",
    "    # Initialize the pynvml library\n",
    "    pynvml.nvmlInit()\n",
    "    \n",
    "    # Get the number of GPU devices\n",
    "    num_gpus = pynvml.nvmlDeviceGetCount()\n",
    "    \n",
    "    # Iterate over GPU devices\n",
    "    for i in range(num_gpus):\n",
    "        # Get the device identifier\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "        # Get the full GPU name\n",
    "        gpu_name = pynvml.nvmlDeviceGetName(handle)\n",
    "        print(\"GPU Name:\", gpu_name)\n",
    "        \n",
    "    # Shutdown the pynvml library\n",
    "    pynvml.nvmlShutdown()\n",
    "else:\n",
    "    print(\"TensorFlow is not using the GPU\")"
   ],
   "id": "a45c005b532337af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is using the GPU\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T17:16:50.576880Z",
     "start_time": "2024-09-13T17:16:50.566878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "video_path = 'GAZE_dataset/video'\n",
    "original_annotation_path = 'GAZE_dataset/annotation_cleaned/'\n",
    "my_annotation_path = 'GAZE_dataset/annotations.csv'\n",
    "patches_path = 'GAZE_dataset/preprocess/video_data/'\n",
    "pca_dir = \"GAZE_dataset/preprocess/fitted_PCA\""
   ],
   "id": "4ffc38c2ecdb6546",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T17:16:50.586875Z",
     "start_time": "2024-09-13T17:16:50.576880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        pickled = pickle.load(f)\n",
    "    return pickled\n",
    "\n",
    "def save_pickle(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f)"
   ],
   "id": "d14224fd38a0145d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Face annotations\n",
    "\n",
    "loop each author annotations to creat my annotations"
   ],
   "id": "7f6fca3e9dd03444"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bounding_box_data = []\n",
    "\n",
    "for i in range(1, 302):\n",
    "    each_annotation = f'NewAnt_{i}.txt'\n",
    "    annotation_path = os.path.join(original_annotation_path, each_annotation)\n",
    "    video_name = f'{i}.mp4'\n",
    "    try:\n",
    "        with open(annotation_path, 'r') as f:\n",
    "            file_lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f'File {annotation_path} not found, the annotation is lost')\n",
    "        continue\n",
    "    for line in file_lines:\n",
    "        if line.strip():\n",
    "            data = line.strip().split(' ')\n",
    "            label = data[9]\n",
    "            if len(data) == 10:\n",
    "                gaze_direction = None\n",
    "                event_attribute = None\n",
    "                atomic_attribute = None\n",
    "            elif len(data) == 13:\n",
    "                gaze_direction = data[-1]\n",
    "                if gaze_direction == 'P1': gaze_direction = f'{label}, Person1'\n",
    "                elif gaze_direction == 'P2': gaze_direction = f'{label}, Person2'\n",
    "                elif gaze_direction == 'P3': gaze_direction = f'{label}, Person3'\n",
    "                elif gaze_direction == 'P4': gaze_direction = f'{label}, Person4'\n",
    "                elif gaze_direction == 'O1': gaze_direction = f'{label}, Object1'\n",
    "                elif gaze_direction == 'O2': gaze_direction = f'{label}, Object2'\n",
    "                elif gaze_direction == 'O3': gaze_direction = f'{label}, Object3'\n",
    "                elif gaze_direction == 'O4': gaze_direction = f'{label}, Object4'\n",
    "                elif gaze_direction == 'O5': gaze_direction = f'{label}, Object5'\n",
    "                elif gaze_direction == 'NA': gaze_direction = None\n",
    "                event_attribute = data[10]\n",
    "                atomic_attribute = data[11]\n",
    "                \n",
    "            frame_data = {'video_name': video_name,\n",
    "                          'frame': int(data[5])+1,\n",
    "                          'label_name': data[9],\n",
    "                          'left': int(data[1]),\n",
    "                          'top' : int(data[2]),\n",
    "                          'right': int(data[3]),\n",
    "                          'bottom': int(data[4]),\n",
    "                          'gaze_direction': gaze_direction,\n",
    "                          'event_attribute': event_attribute,\n",
    "                          'atomic_attribute': atomic_attribute,\n",
    "                          }\n",
    "            bounding_box_data.append(frame_data)"
   ],
   "id": "41720809e12e39bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "annotations = pd.DataFrame(bounding_box_data)\n",
    "annotations"
   ],
   "id": "cdb03c90ac48f499",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "annotations.to_csv(my_annotation_path, index=False)",
   "id": "427879afbea1068b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CROP OUT IMAGES PATCHES FROM VIDEOS\n",
   "id": "faa13c7ea0fa06b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "annotations = pd.read_csv(my_annotation_path)\n",
    "annotations"
   ],
   "id": "1b44c7c8ed295e4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Iterate over each unique video in the DataFrame\n",
    "for video_name in tqdm(annotations['video_name'].unique()):\n",
    "    # print(\"Processing video:\", video_name)\n",
    "    # Fetch all frames annotations in this video\n",
    "    save_path = os.path.join(patches_path, video_name)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    video = cv2.VideoCapture(os.path.join(video_path, video_name))\n",
    "    video_annotations = annotations[annotations['video_name'] == video_name]\n",
    "    patches = []\n",
    "    annotations_dict = {'labels': [], 'frame_numbers': [], \n",
    "                        'left': [], 'right': [], 'top': [], 'bottom': [],\n",
    "                        'gaze_direction': [], 'event_attribute': [], 'atomic_attribute': []}\n",
    "    \n",
    "    for current_frame in range(1, video_annotations['frame'].iloc[-1]+1):  # in the range of number of frames\n",
    "        successful_read, frame = video.read()\n",
    "        if successful_read:\n",
    "            # Filter annotations for the current frame\n",
    "            frame_annotations = video_annotations[video_annotations['frame'] == current_frame]\n",
    "            if not frame_annotations.empty:\n",
    "                for _, entity in frame_annotations.iterrows():\n",
    "                    patches.append(frame[int(entity['top']):int(entity['bottom']),int(entity['left']):int(entity['right'])])\n",
    "                    annotations_dict['labels'].append(entity['label_name'])\n",
    "                    annotations_dict['frame_numbers'].append(current_frame)\n",
    "                    annotations_dict['left'].append(int(entity['left']))\n",
    "                    annotations_dict['right'].append(int(entity['right']))\n",
    "                    annotations_dict['top'].append(int(entity['top']))\n",
    "                    annotations_dict['bottom'].append(int(entity['bottom']))\n",
    "                    annotations_dict['gaze_direction'].append(entity['gaze_direction'])\n",
    "                    annotations_dict['event_attribute'].append(entity['event_attribute'])\n",
    "                    annotations_dict['atomic_attribute'].append(entity['atomic_attribute'])\n",
    "                    \n",
    "        else:\n",
    "            raise ValueError(f\"Unsuccessful read frame {current_frame} of {video_name}\")\n",
    "    save_pickle(patches, os.path.join(save_path, 'patches'))\n",
    "    annotation_df = pd.DataFrame(annotations_dict)\n",
    "    save_pickle(annotation_df, os.path.join(save_path, 'annotations'))\n"
   ],
   "id": "35e6f1cb3642d7bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " def visualize_patches(num_patches_to_display=10):\n",
    "    # Get a list of all subdirectories in the patches_output_path directory\n",
    "    videos = [d for d in os.listdir(patches_path)]\n",
    "    import random\n",
    "    # Randomly select one of the subdirectories\n",
    "    selected_subdir = random.choice(videos)\n",
    "    selected_path = os.path.join(patches_path, selected_subdir)\n",
    "    \n",
    "    patches = load_pickle(os.path.join(selected_path, 'patches'))\n",
    "    annot = load_pickle(os.path.join(selected_path, 'annotations'))\n",
    "    \n",
    "    # Display each patch with its corresponding labels\n",
    "    print(len(patches))\n",
    "    for i, patch in enumerate(patches):\n",
    "        print(annot.loc[i, 'frame_numbers'])\n",
    "        print(annot.loc[i, 'labels'])\n",
    "        print(annot.loc[i, 'gaze_direction'])\n",
    "        plt.imshow(cv2.cvtColor(patch, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        if i+2> num_patches_to_display:\n",
    "            break\n"
   ],
   "id": "8a9e019c0a34fe97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_patches(5)",
   "id": "e7abcecc8a759b74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## VGG FEATURES",
   "id": "c4107393b9f5de3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import smart_resize\n",
    "from tensorflow.keras.models import Model"
   ],
   "id": "4250f26d27887b03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def reshape_patches(x):\n",
    "    temp = np.expand_dims(x, axis=0)\n",
    "    temp2 = preprocess_input(smart_resize(temp, (224,224)))\n",
    "    return temp2[0]"
   ],
   "id": "d97c96001ee8d75d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)"
   ],
   "id": "e229246bc623ece8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "restart = input('Do you want to reparse the input videos? (y/n)')",
   "id": "b5306c00d6202bdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 32  # Adjust this batch size based on your memory capacity\n",
    "\n",
    "for video in tqdm(os.listdir(patches_path)):\n",
    "    video_dir = os.path.join(patches_path, video)\n",
    "    patch_dir = os.path.join(video_dir, \"patches\")\n",
    "    out_dir = os.path.join(video_dir, \"VGG19_patches\")\n",
    "    if not os.path.exists(out_dir) or restart == 'y':\n",
    "        patches = load_pickle(patch_dir)\n",
    "        y_total = []\n",
    "        \n",
    "        for i in range(0, len(patches), batch_size):\n",
    "            batch_patches = patches[i:i + batch_size]\n",
    "            x_batch = [reshape_patches(patch) for patch in batch_patches]\n",
    "            x_batch = np.array(x_batch)\n",
    "            y_batch = model.predict(x_batch, verbose=0)\n",
    "            y_total.extend(y_batch)\n",
    "        \n",
    "        y_total = np.array(y_total)\n",
    "        save_pickle(y_total, out_dir)\n",
    "        print(f\"VGG19 patches saved to {video_dir}\")\n"
   ],
   "id": "d22d20d67adbdfe6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "324ac20b8cbe2cc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fit PCA",
   "id": "53b6fbefae196191"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "id": "1f687660168dae0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_all_vggfeatures():\n",
    "    all_features = []\n",
    "    for video in tqdm(os.listdir(patches_path)):\n",
    "        patch_dir = os.path.join(patches_path, video, \"VGG19_patches\")\n",
    "        all_features.extend(load_pickle(patch_dir))\n",
    "\n",
    "    all_features = np.array(all_features)\n",
    "    print(all_features.shape)\n",
    "    return all_features\n",
    "\n",
    "\n",
    "def fit_pca(all_features):\n",
    "    pca = PCA(n_components=20)\n",
    "    scaler = StandardScaler()\n",
    "    all_features_scaled = scaler.fit_transform(all_features)\n",
    "    pca.fit(all_features_scaled)\n",
    "    return pca, scaler"
   ],
   "id": "be6708392c21fa97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pca, scaler = fit_pca(extract_all_vggfeatures())",
   "id": "bb02d471c3f7ac3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_pickle(pca, os.path.join(pca_dir, \"pca\"))\n",
    "save_pickle(scaler, os.path.join(pca_dir, \"scaler\"))"
   ],
   "id": "6a5170e5f76866ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PCA on VGG features",
   "id": "9549c5f8d82c126f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pca = load_pickle(os.path.join(pca_dir, \"pca\"))\n",
    "scaler = load_pickle(os.path.join(pca_dir, 'scaler'))"
   ],
   "id": "8af163c062d01c8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for video in tqdm(os.listdir(patches_path)):\n",
    "    video_dir = os.path.join(patches_path, video)\n",
    "    patch_dir = os.path.join(video_dir, \"VGG19_patches\")\n",
    "    vgg_features = load_pickle(patch_dir)\n",
    "    scaled_features = scaler.transform(vgg_features)\n",
    "    pca_features = pca.transform(scaled_features)\n",
    "    save_pickle(pca_features, os.path.join(video_dir, \"pca_features\"))   "
   ],
   "id": "cafbf53d112df457",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Node Features\n",
   "id": "f83d5c32898610c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for video in tqdm(os.listdir(patches_path)):\n",
    "    video_dir = os.path.join(patches_path, video)\n",
    "    pca_features = load_pickle(os.path.join(video_dir, \"pca_features\"))\n",
    "    video_annot = load_pickle(os.path.join(video_dir, \"annotations\"))\n",
    "    new_features = []\n",
    "    for i, patch_feature in enumerate(pca_features):\n",
    "        new_feature = np.append(patch_feature, [video_annot['top'][i], video_annot['bottom'][i], video_annot['left'][i], video_annot['right'][i]])\n",
    "        new_feature = np.append(new_feature, [0] if 'Person' in video_annot['labels'][i] else [1])\n",
    "        assert len(new_feature) == 25\n",
    "        new_features.append(new_feature)\n",
    "    video_annot['features'] = new_features\n",
    "    save_pickle(video_annot, os.path.join(video_dir, \"annotations\"))"
   ],
   "id": "6c92a99d2e2d0b5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "video_annot",
   "id": "a52731bcca7f31a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split into Sequences",
   "id": "93a0ca61ce418fef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def split_sequences(dir, df):\n",
    "    splits = []\n",
    "    labels = []\n",
    "    start_index = 0\n",
    "    \n",
    "    # Get the unique frame numbers\n",
    "    unique_frames = df['frame_numbers'].unique()\n",
    "    \n",
    "    # Create a pair for the first frame, handling NaNs\n",
    "    frame_labels = df[df['frame_numbers'] == unique_frames[0]]['labels'].tolist()\n",
    "    frame_events = df[df['frame_numbers'] == unique_frames[0]]['event_attribute'].tolist()\n",
    "    frame_events = [None if isinstance(x, float) else x for x in frame_events]\n",
    "    previous_pairs = dict(zip(frame_labels, frame_events))\n",
    "\n",
    "    sequences = []\n",
    "    one_sequence = []\n",
    "    frame_features = df[df['frame_numbers'] == unique_frames[0]]['features'].tolist()\n",
    "    combined_tuple = list(zip(frame_labels, frame_events))\n",
    "    frame_matrix = np.empty((2, len(frame_labels)), dtype=object)\n",
    "    for j in range(len(frame_labels)):\n",
    "        frame_matrix[0, j] = frame_features[j]\n",
    "        frame_matrix[1, j] = combined_tuple[j]\n",
    "    one_sequence.append(frame_matrix)\n",
    "    \n",
    "    for i in range(1, len(unique_frames)):\n",
    "        frame = unique_frames[i]\n",
    "        # Create a pair for the current frame, handling NaNs        \n",
    "        frame_labels = df[df['frame_numbers'] == frame]['labels'].tolist()\n",
    "        frame_events = df[df['frame_numbers'] == frame]['event_attribute'].tolist()\n",
    "        frame_events = [None if isinstance(x, float) else x for x in frame_events]\n",
    "        current_pairs = dict(zip(frame_labels, frame_events))\n",
    "        \n",
    "        frame_features = df[df['frame_numbers'] == frame]['features'].tolist()\n",
    "        combined_tuple = list(zip(frame_labels, frame_events))\n",
    "        frame_matrix = np.empty((2, len(frame_labels)), dtype=object)\n",
    "        for j in range(len(frame_labels)):\n",
    "            frame_matrix[0, j] = frame_features[j]\n",
    "            frame_matrix[1, j] = combined_tuple[j]\n",
    "        \n",
    "\n",
    "        # Check if there's any difference in pairs\n",
    "        if current_pairs != previous_pairs:\n",
    "            labels.append(previous_pairs)\n",
    "            sequences.append(np.array(one_sequence, dtype=object))\n",
    "            one_sequence = [frame_matrix]\n",
    "            # Update the previous pairs\n",
    "            previous_pairs = current_pairs\n",
    "            splits.append(df[df['frame_numbers'].isin(unique_frames[start_index:i])])\n",
    "            start_index = i\n",
    "        else:\n",
    "            one_sequence.append(frame_matrix)\n",
    "\n",
    "    # Append the last segment\n",
    "    sequences.append(np.array(one_sequence, dtype=object))\n",
    "    labels.append(previous_pairs)\n",
    "    splits.append(df[df['frame_numbers'].isin(unique_frames[start_index:])])\n",
    "    # Save all the sequences\n",
    "    for i, split in enumerate(splits):\n",
    "        save_pickle(split, os.path.join(dir, f\"sequence_{i}\"))\n",
    "    save_pickle(sequences, os.path.join(dir,'stupid_sequences'))\n",
    "    save_pickle(labels, os.path.join(dir, f\"labels\"))"
   ],
   "id": "ff9dbdd22742688c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for video in tqdm(os.listdir(patches_path)):\n",
    "    video_dir = os.path.join(patches_path, video)\n",
    "    video_annot = load_pickle(os.path.join(video_dir, \"annotations\"))\n",
    "    split_sequences(video_dir, video_annot)"
   ],
   "id": "35565641c30914a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparing preprocessed results",
   "id": "d863d73ed5b2fc15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test = load_pickle('GAZE_dataset/preprocess/video_data/1.mp4/sequences')\n",
    "test_label = load_pickle('GAZE_dataset/preprocess/video_data/1.mp4/labels')"
   ],
   "id": "fd878a9326b142a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test",
   "id": "ac91ec8b063d33e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5ca9c6acef503cfb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "281， 222， 329， 221\n",
    "rig, left, bot, top\n",
    "top, bot, lef, rig"
   ],
   "id": "d2445e8e007377ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_label",
   "id": "fa12d4278fc8037",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "manasi_test = load_pickle('GAZE_dataset/Manasi_preprocessed_pickles/processed_Mar25_0')",
   "id": "8b1cf4fecebde1b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# video names\n",
    "manasi_test.keys()"
   ],
   "id": "3de53e6471916ff6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# each video dict\n",
    "manasi_test['1'].keys()"
   ],
   "id": "a7012c82906a6b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "manasi_test['1']['labels']",
   "id": "1ccaac3dfc6c0a26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# len is the sequence number, this video only has 1 sequence\n",
    "type(manasi_test['1']['graph_dicts']), len(manasi_test['1']['graph_dicts'])"
   ],
   "id": "fa7ac93e6dcfebbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# here is the number of frames in this sequence\n",
    "type(manasi_test['1']['graph_dicts'][0]), len(manasi_test['1']['graph_dicts'][0])"
   ],
   "id": "4d544766fa75ec64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(manasi_test['1']['graph_dicts'][0][0]), len(manasi_test['1']['graph_dicts'][0][0])",
   "id": "40a822df7e04dcc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# here is the graph info of the first frame in the sequence\n",
    "manasi_test['1']['graph_dicts'][0][0]"
   ],
   "id": "f5a7a0e93d9e4a0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(manasi_test['1']['sequences']), type(manasi_test['1']['sequences'])",
   "id": "ddf4d7ac30dc5253",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# in this sequence there are 389 frames\n",
    "manasi_test['1']['sequences'][0].shape, type(manasi_test['1']['sequences'][0])"
   ],
   "id": "ba2241f28641fbe4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "manasi_test['1']['sequences'][0][0].shape, type(manasi_test['1']['sequences'][0][0])",
   "id": "51cdddc9016e48a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# here is the entity info of the first frame\n",
    "manasi_test['1']['sequences'][0][0]"
   ],
   "id": "4c7bb2f2da120cf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(manasi_test['1']['sequences'][0][0][0][0])",
   "id": "ce9ed6acb0bc4676",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# labels of this video\n",
    "manasi_test['1']['labels']"
   ],
   "id": "72c499247e9e3628",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# each is the label of the sequence\n",
    "manasi_test['12']['labels']"
   ],
   "id": "a8db0af8bf7de34b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "dict of video names --> sequence --> sequences --> frames --> [0] frame feature (np array of lists, each list is a 25 dimension of feature)[1] frame label",
   "id": "a12c98414cc91a11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "manasi_test['1']['sequences'][0][0][0]",
   "id": "7e8d0c6a62c748db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "(manasi_test['1']['sequences'][0][0].shape)",
   "id": "2c3a31779fd14aad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "manasi_test['1']['sequences'][0][0][0][0]",
   "id": "5c1a75e4880428c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "manasi_test['1']['sequences'][0][0]",
   "id": "23ae94ab03cabdb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "manasi_test['1']['sequences'][0][0][1]\n",
   "id": "d1df84524f030639",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.array([1, 2, 3])",
   "id": "9e4eea382c24826c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "dict of all videos --> dict of ['graph_dicts', 'sequences', 'labels'] for each video -->\n",
    "\n",
    "graph_dicts list of all sequences' graph dicts --> list of graph dicts for each frame --> \n"
   ],
   "id": "7ee9fa96c4e3975d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "load_pickle('GAZE_dataset/preprocess/video_data/1.mp4/sequence_0')",
   "id": "df3b77d441fbc9ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build Graph\n",
   "id": "571be050246999b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:58:20.927774Z",
     "start_time": "2024-09-13T15:58:20.897752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_sequence(sequence_annotations):\n",
    "    \n",
    "    all_labels = ['Person1', 'Person2', 'Person3', 'Person4', 'Object1', 'Object2', 'Object3', 'Object4', 'Object5']\n",
    "    grouped = sequence_annotations.groupby('frame_numbers')\n",
    "    graph_dicts_frames = []\n",
    "    for frame_number, group in grouped:\n",
    "        senders, receivers, nodes = [], [], []\n",
    "\n",
    "        # Process in the order of the all_labels list\n",
    "        entities = []\n",
    "        for entity in all_labels:                \n",
    "            if (group['labels'] == entity).any():\n",
    "                entities.append(entity)\n",
    "                \n",
    "        for i, entity in enumerate(entities):\n",
    "            # Access the value in the 'features' and 'gazes' columns of that entity\n",
    "            feature = group.loc[group['labels'] == entity, 'features'].iloc[0].tolist()\n",
    "            nodes.append(feature)\n",
    "            edge = group.loc[group['labels'] == entity, 'gaze_direction'].iloc[0]\n",
    "            # if gaze exists (only when the entity is person)\n",
    "            if not isinstance(edge, float):\n",
    "                sender, receiver = edge.split(', ')\n",
    "                # if the gaze is at some entities not found in the video, the gaze will be discarded\n",
    "                if sender == entity and receiver in entities: \n",
    "                    senders.append(i)\n",
    "                    receivers.append(entities.index(receiver))\n",
    "                # else:\n",
    "                #     print(f'unrecognised gaze {edge} in {entities}')\n",
    "        while len(nodes) < 5:\n",
    "            nodes.append([0 for _ in range(25)])\n",
    "    \n",
    "        assert len(nodes) >= 5\n",
    "        graph_dict = {'nodes': nodes, 'senders': senders, 'receivers': receivers}\n",
    "        graph_dicts_frames.append(graph_dict)\n",
    "    return graph_dicts_frames"
   ],
   "id": "cdc832d4bcecf849",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:02:26.199429Z",
     "start_time": "2024-09-13T15:58:21.804807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_videos = {}\n",
    "for video_name in tqdm(sorted(os.listdir(patches_path))):\n",
    "    \n",
    "    video_dir = os.path.join(patches_path, video_name)\n",
    "    video_data = {'graph_dicts': [],\n",
    "                  # 'sequences': [],\n",
    "                  'labels': load_pickle(os.path.join(video_dir, 'labels'))}\n",
    "    graph_dicts_sequences = []\n",
    "    \n",
    "    for pickle_name in os.listdir(video_dir):\n",
    "        if 'sequence_' in pickle_name:\n",
    "            sequence_annotations = load_pickle(os.path.join(video_dir, pickle_name))\n",
    "            graph_dicts_sequences.append(process_sequence(sequence_annotations))\n",
    "    video_data['graph_dicts'] = graph_dicts_sequences\n",
    "    all_videos[video_name.replace('.mp4', '')] = video_data"
   ],
   "id": "f6eff4d74838c831",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 285/299 [04:00<00:11,  1.19it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "save_pickle(all_videos, \"GAZE_dataset/preprocess/graphs\")",
   "id": "952c4904ace897b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_videos = load_pickle(\"GAZE_dataset/preprocess/graphs\")",
   "id": "34d71b1c5a3a3328",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def check(data1, data2):\n",
    "    import random\n",
    "\n",
    "    # Generate 10 random integers\n",
    "    random_integers = [str(random.randint(1, 299)) for _ in range(100)]\n",
    "    \n",
    "    assert list(data1.keys()) == list(data2.keys())\n",
    "    for i in tqdm(random_integers):\n",
    "        if i in ['255', '291']:\n",
    "            continue\n",
    "        if data1[i]['labels'] != data2[i]['labels']:\n",
    "            print(f'{i} labels do not match')\n",
    "        if len(data1[i]['graph_dicts']) != len(data2[i]['graph_dicts']):\n",
    "            print(f'{i} graph_dicts do not match')\n",
    "        if len(data1[i]['graph_dicts'][0]) != len(data2[i]['graph_dicts'][0]): \n",
    "            print(f'{i} graph_dicts[0] do not match')\n",
    "        assert len(data1[i]['graph_dicts'][0][0]) == len(data2[i]['graph_dicts'][0][0])\n",
    "    \n",
    "    random_int = str(random.randint(1, 299))\n",
    "    print(f'========== check the following {random_int}')\n",
    "    print(data1[random_int]['graph_dicts'][0][0])\n",
    "    print(data2[random_int]['graph_dicts'][0][0])\n",
    "        "
   ],
   "id": "39b4e2c31b7f0a32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "check(V, all_videos)",
   "id": "5dd768aba8568caa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "V.keys()",
   "id": "3d86b6263f12a89f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:03:10.943342Z",
     "start_time": "2024-09-13T16:03:10.912080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for node in V['1']['graph_dicts'][0][0]['nodes']:\n",
    "    print(node)"
   ],
   "id": "fc858e76039f1be1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.127209432632547, -1.0256831867282694, 8.13335232314885, -4.201163709443032, 1.8991420331250286, -13.876740169041135, -5.526908531131593, -3.8356414133755274, 9.519650781813894, -3.851486033541, -10.705018150235949, -5.2528136370278915, -1.2222795299178517, 2.5200896122278476, -1.901773983292112, -0.8833180093497349, -0.5375356957939621, -4.3363662521959885, 3.3842700418425578, -3.2342044946744766, 221, 329, 222, 281, 1]\n",
      "[-10.227210662910501, -7.964693699370105, 12.540352411872792, -11.681789480086213, 0.30675131708999126, -10.135767468020056, -5.339033053269009, -1.821363372032125, 5.746255099644273, -0.02389578031439287, -6.916765072423783, 8.810839903650729, 1.9119219721072658, 3.520538773271611, 6.203606830129152, 7.181162217732476, -3.5985563941815815, -0.4146291782533541, 6.5097611640900555, 1.183150324798416, 54, 225, 104, 219, 0]\n",
      "[-12.812543674851636, -16.574032737620364, 5.022561399135988, -1.9710347021824894, -4.590026455200244, -14.132404203224567, 3.5610422346674504, -2.152768956237242, 9.752300526531194, -5.934178701440138, 7.906169869012861, -4.110902741132687, 2.4604946333069417, 5.639692802635624, 4.779487860544534, 1.6455319386440521, -3.6249220467071455, -0.9593423312896159, 0.4130565702495333, -1.7666946038529956, 46, 213, 402, 533, 0]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:03:21.255586Z",
     "start_time": "2024-09-13T16:03:21.239927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for node in all_videos['1']['graph_dicts'][0][0]['nodes']:\n",
    "    print(node)"
   ],
   "id": "748f32c9ab51fbb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.227222442626953, 7.964751243591309, 12.540274620056152, -11.68178653717041, 0.30670633912086487, 10.135627746582031, -5.338925838470459, -1.823194146156311, -5.744480609893799, 0.027499111369252205, -6.921828269958496, -8.80478572845459, 1.9131251573562622, -3.541015863418579, 6.224554061889648, 7.135051250457764, 3.634446144104004, -0.4626026749610901, 6.491567611694336, 1.4666532278060913, 54.0, 225.0, 104.0, 219.0, 0.0]\n",
      "[12.812554359436035, 16.574092864990234, 5.022436141967773, -1.971082329750061, -4.589867115020752, 14.132447242736816, 3.5617623329162598, -2.1517295837402344, -9.754671096801758, 5.933873176574707, 7.9097981452941895, 4.132099151611328, 2.4401583671569824, -5.6511383056640625, 4.711540699005127, 1.6954163312911987, 3.5094573497772217, -1.1490932703018188, 0.43998879194259644, -2.007664918899536, 46.0, 213.0, 402.0, 533.0, 0.0]\n",
      "[-19.127185821533203, 1.0257126092910767, 8.133258819580078, -4.2011542320251465, 1.8991039991378784, 13.876609802246094, -5.526852607727051, -3.836113452911377, -9.521496772766113, 3.8565902709960938, -10.70484447479248, 5.255104064941406, -1.2350571155548096, -2.520430088043213, -1.907051920890808, -0.9123398661613464, 0.2712787687778473, -4.209105491638184, 3.4116199016571045, -3.3596458435058594, 221.0, 329.0, 222.0, 281.0, 1.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T17:32:21.881607Z",
     "start_time": "2024-09-13T17:32:18.583051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "V = {}\n",
    "with open('GAZE_dataset/Manasi_preprocessed_pickles/processed_Mar25_0', 'rb') as f:\n",
    "    V.update(pickle.load(f))\n",
    "\n",
    "with open('GAZE_dataset/Manasi_preprocessed_pickles/processed_Mar25_100', 'rb') as f:\n",
    "    V.update(pickle.load(f))\n",
    "\n",
    "with open('GAZE_dataset/Manasi_preprocessed_pickles/processed_Mar25_200', 'rb') as f:\n",
    "    V.update(pickle.load(f))\n",
    "\n",
    "\n",
    "myKeys = list(V.keys())\n",
    "myKeys.sort()\n",
    "V = {i: V[i] for i in myKeys}"
   ],
   "id": "5021f387e5d7a90a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T17:32:22.825058Z",
     "start_time": "2024-09-13T17:32:22.548374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "bootstrapping = 10\n",
    "from sklearn.model_selection import train_test_split\n",
    "mode = 'standard'"
   ],
   "id": "e344e0e2e11ac0e4",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:16:32.373386Z",
     "start_time": "2024-09-13T16:16:05.174628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_label_anomalies(seq_labels):\n",
    "\tcounts = Counter(seq_labels)\n",
    "\tif 'JointAtt' in counts.keys() and counts['JointAtt'] == 1:\n",
    "\t\treturn False\n",
    "\telif 'MutualGaze' in counts.keys() and counts['MutualGaze'] == 1:\n",
    "\t\treturn False\n",
    "\telif 'NA' in counts.keys() and counts['NA'] >= 1:\n",
    "\t\treturn False\n",
    "\telse:\n",
    "\t\treturn True\n",
    "errors = []\n",
    "for i in range(bootstrapping):\n",
    "    ### Split Videos into train and test (stratify not possible because will have to separate labels then)\n",
    "    V_train_idx, V_test_idx = train_test_split(list(V.keys()), random_state=123+i) #5Jun = 13+i, 14Jun = 27+i, 14eveJun = 123 +i\n",
    "    Sequences = []\n",
    "    seq_train_idx = []\n",
    "    seq_test_idx = []\n",
    "    for k in V_train_idx:\n",
    "        # print(V_train_idx)\n",
    "        # print(k)\n",
    "        seq_labels = [tuple(v for k,v in seq.items() if k[0]=='P') for seq in V[k]['labels']]\n",
    "        for ind, seq in enumerate(seq_labels):\n",
    "            if check_label_anomalies(seq) and len(seq)>=2 and len(V[k]['labels'][ind])<=5:  #remove this last condition later\n",
    "                Seq_dict = dict()\n",
    "                Seq_dict['label'] = seq[::-1]  # reversing RETHINK THIS\n",
    "\t\t\t\t# reverse node features (keeping last two persons ahead) ##RETHINK THIS\n",
    "                for frame_id in range(len(V[k]['graph_dicts'][ind])):\n",
    "                    node_features = np.array(V[k]['graph_dicts'][ind][frame_id]['nodes'])\n",
    "                    V[k]['graph_dicts'][ind][frame_id]['nodes'] = node_features[::-1].tolist()\n",
    "    # \n",
    "    #                 if mode == \"standard\":\n",
    "                    padding = np.zeros((5-len(node_features),node_features.shape[1])).tolist()\n",
    "                    V[k]['graph_dicts'][ind][frame_id]['nodes'].extend(padding)\n",
    "\n",
    "                    \n",
    "                Seq_dict['graph_dicts'] = V[k]['graph_dicts'][ind]\n",
    "                for j in range(len(Seq_dict['graph_dicts'])):\n",
    "                    if Seq_dict['graph_dicts'][j]['nodes'][0] == [0 for _ in range(25)]:\n",
    "                        # print(seq_labels)\n",
    "                        errors.append([i, k, ind, j])\n",
    "            \n",
    "                    \n",
    "                # seq_train_idx.append(len(Sequences))\n",
    "                # Sequences.append(Seq_dict)\n",
    "        #     break\n",
    "        # break\n",
    "    #   \n",
    "\t# for k in V_test_idx:\n",
    "\t# \tseq_labels = [tuple(v for k,v in seq.items() if k[0]=='P') for seq in V[k]['labels']]\n",
    "\t# \tfor ind, seq in enumerate(seq_labels):\n",
    "\t# \t\tif check_label_anomalies(seq) and len(seq)>=2 and len(V[k]['labels'][ind])<=5:  #remove this last condition later\n",
    "\t# \t\t\tSeq_dict = dict()\n",
    "\t# \t\t\tSeq_dict['label'] = seq[::-1]  # reversing RETHINK THIS\n",
    "    # \n",
    "\t# \t\t\t# reverse node features (keeping last two persons ahead) ##RETHINK THIS\n",
    "\t# \t\t\tfor frame_id in range(len(V[k]['graph_dicts'][ind])):\n",
    "\t# \t\t\t\tnode_features = np.array(V[k]['graph_dicts'][ind][frame_id]['nodes'])\n",
    "\t# \t\t\t\tV[k]['graph_dicts'][ind][frame_id]['nodes'] = node_features[::-1].tolist()\n",
    "    # \n",
    "\t# \t\t\t\tif mode == \"standard\":\n",
    "\t# \t\t\t\t\tpadding = np.zeros((5-len(node_features),node_features.shape[1])).tolist()\n",
    "\t# \t\t\t\t\tV[k]['graph_dicts'][ind][frame_id]['nodes'].extend(padding)\n",
    "    # \n",
    "\t# \t\t\tSeq_dict['graph_dicts'] = V[k]['graph_dicts'][ind]\n",
    "    # \n",
    "\t# \t\t\tseq_test_idx.append(len(Sequences))\n",
    "\t# \t\t\tSequences.append(Seq_dict)\n",
    "    # \n",
    "\t# print(\"Train Seqs\", len(seq_train_idx), \"Test Seqs\", len(seq_test_idx))\n"
   ],
   "id": "62f8acebf48e0a79",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:16:32.404021Z",
     "start_time": "2024-09-13T16:16:32.377737Z"
    }
   },
   "cell_type": "code",
   "source": "errors[0]",
   "id": "b2a37b121d23d2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, '15', 0, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:05:30.222412Z",
     "start_time": "2024-09-13T16:05:30.206733Z"
    }
   },
   "cell_type": "code",
   "source": "V['37']['graph_dicts'][1][134]",
   "id": "df44a3b1375055d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': [[-3.0686977176502137,\n",
       "   -16.462693322343235,\n",
       "   12.819795932345222,\n",
       "   -3.1687428067800476,\n",
       "   -1.0203585893875724,\n",
       "   5.682883175930007,\n",
       "   -2.2786209917925815,\n",
       "   -5.218296999587048,\n",
       "   4.848294112234644,\n",
       "   -0.4699461901103268,\n",
       "   6.557035838865493,\n",
       "   -0.5260438243443568,\n",
       "   -7.303968359671414,\n",
       "   0.9738747281569077,\n",
       "   0.2538767715917672,\n",
       "   -1.8761696228337952,\n",
       "   1.8352606381298984,\n",
       "   -4.117292776096059,\n",
       "   0.5040785413039112,\n",
       "   -3.609829107573127,\n",
       "   33.0,\n",
       "   107.0,\n",
       "   385.0,\n",
       "   448.0,\n",
       "   0.0],\n",
       "  [11.906825422187474,\n",
       "   -11.88630108407816,\n",
       "   11.403745932411425,\n",
       "   5.200955818868563,\n",
       "   8.435605397522327,\n",
       "   -0.42978243503074176,\n",
       "   -9.313480966028855,\n",
       "   13.25618719898381,\n",
       "   7.87509784261819,\n",
       "   -3.829458400099795,\n",
       "   3.84527633095601,\n",
       "   -5.525571142829749,\n",
       "   -9.939142198350574,\n",
       "   0.4804799593785418,\n",
       "   -4.396122704360587,\n",
       "   1.092364898776514,\n",
       "   -1.353065360662791,\n",
       "   -5.479873354656828,\n",
       "   7.082500051582039,\n",
       "   -3.7794243579538302,\n",
       "   36.0,\n",
       "   107.0,\n",
       "   301.0,\n",
       "   365.0,\n",
       "   0.0],\n",
       "  [14.876560202501313,\n",
       "   11.65483705289568,\n",
       "   4.491677477414241,\n",
       "   2.413672036856762,\n",
       "   0.4281147055820918,\n",
       "   -9.6374787010718,\n",
       "   -7.490225435282849,\n",
       "   -10.973546251555717,\n",
       "   -6.088320740130678,\n",
       "   8.152283235199553,\n",
       "   -0.0455524182476964,\n",
       "   4.770887821587439,\n",
       "   -6.75228455883264,\n",
       "   3.303494337485807,\n",
       "   5.524091780317515,\n",
       "   6.158877674313495,\n",
       "   -2.506975522113677,\n",
       "   -4.281494299069744,\n",
       "   0.21210415137536537,\n",
       "   3.3369211651329334,\n",
       "   26.0,\n",
       "   108.0,\n",
       "   144.0,\n",
       "   216.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]],\n",
       " 'senders': [0, 1, 2],\n",
       " 'receivers': [2, 0, 0]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(Sequences)",
   "id": "306cd4bca8fbe237",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(Sequences[0]), len(Sequences[0]), Sequences[0].keys()",
   "id": "1d82bc379a9a47c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Sequences[0]['label']",
   "id": "fe404b16c3cae677",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(Sequences[0]['graph_dicts'])",
   "id": "a04832337b918b4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(Sequences[0]['graph_dicts'][0]['nodes'])",
   "id": "ce402322db987c91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Sequences[-3]['graph_dicts'][0]['nodes']",
   "id": "1edd9218ae81b674",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "s = load_pickle('GAZE_dataset/manasi_bootstrapped/traintest_seqs_5Jun23_9')",
   "id": "7aaed5d6495c4ffa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(s)",
   "id": "a9d90fc3983cb510",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(s), len(s)",
   "id": "fbb9af0c27bbd67c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(s[0]), len(s[0]), s[0].keys()",
   "id": "76922c6d438e4ef2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(s[1]['graph_dicts'])",
   "id": "ab4dbc0218037fb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "s[1]['graph_dicts'][0]['nodes'][0]",
   "id": "88119158dfc31867",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "369aa5899647a221",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:08:04.980475Z",
     "start_time": "2024-09-13T16:06:43.259910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for f in os.listdir('GAZE_dataset/manasi_bootstrapped'):\n",
    "    file_name = os.path.join('GAZE_dataset/manasi_bootstrapped', f)\n",
    "    idx = \"_\".join(file_name.split('_')[-2:])\n",
    "    Sequence = load_pickle(file_name)\n",
    "    print(file_name)\n",
    "    errors = []\n",
    "    for i in range(len(Sequence)):\n",
    "        for j in range(len(Sequence[i]['graph_dicts'])):\n",
    "            if Sequence[i]['graph_dicts'][j]['nodes'][0] == [0 for _ in range(25)]:\n",
    "                # print(seq_labels)\n",
    "                errors.append([idx, i, j])\n",
    "        "
   ],
   "id": "b236f2b5c84229b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_14Jun23_0\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_14Jun23_1\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_14Jun23_2\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_14Jun23_3\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_14Jun23_4\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_14Jun23_5\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_14Jun23_6\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_14Jun23_7\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_14Jun23_8\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_14Jun23_9\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_5Jun23_0\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_5Jun23_1\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_5Jun23_2\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_5Jun23_3\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_5Jun23_4\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_5Jun23_5\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_5Jun23_6\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_5Jun23_7\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_5Jun23_8\n",
      "GAZE_dataset/manasi_bootstrapped\\traintest_seqs_5Jun23_9\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(errors)",
   "id": "fa782a59ef5ba82f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:17:07.537299Z",
     "start_time": "2024-09-13T16:17:07.444784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "boot_set = None\n",
    "for error in errors:\n",
    "    if error[0] != boot_set:\n",
    "        print(error[0])\n",
    "        boot_set = error[0]"
   ],
   "id": "3142074c654a9779",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "errors[0]",
   "id": "1bfd411c083d5967",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "column_index = 1\n",
    "unique_values = set(row[column_index] for row in errors)\n",
    "\n",
    "# Converting the set back to a list if needed\n",
    "unique_values = list(unique_values)\n",
    "\n",
    "print(unique_values)"
   ],
   "id": "9951a03e39495a76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T17:56:26.007459Z",
     "start_time": "2024-09-13T17:56:23.231683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "s = load_pickle('GAZE_dataset/manasi_bootstrapped/traintest_seqs_5Jun23_9')\n",
    "\n",
    "for feat in s[1]['graph_dicts'][0]['nodes']:\n",
    "    print(feat)"
   ],
   "id": "c77a0faa2830f0c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[-13.818248182769008, -10.476121501397772, 3.368019906217009, -9.782118738309396, -4.510680902946422, -1.1619046727240887, 3.5071690343794746, -6.323518275572182, -3.9789037548364092, -9.397165925527396, 9.796443549520045, 0.15798833771417098, -5.717554018561345, 1.1535469727325642, 1.9779028051724334, -5.4560061613642095, -3.955755922377748, -4.181292693076908, -13.769082497516512, -3.9039636901543795, 72.0, 259.0, 148.0, 300.0, 0.0]\n",
      "[-9.746132097891433, -11.380606163767357, -8.166118808729234, 2.552620620316964, -5.049897747516092, 1.4793527744497919, -1.5685977208771757, -0.6680178920360503, -5.550115972844827, -6.08740206570223, -1.072073006648472, 3.152883271393181, -4.781716185524992, -2.784124535487983, 6.294474572776544, -1.0976291579327584, -2.6049036082408303, -6.645824214564527, -4.9528906727874915, -3.3243301940910186, 4.0, 185.0, 354.0, 516.0, 0.0]\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "s[2]['graph_dicts'][1]['nodes']\n",
   "id": "cf56d8a331e16835",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check how many videos have more than 2 people",
   "id": "df1af14ac20627aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T17:17:51.745271Z",
     "start_time": "2024-09-13T17:17:51.714071Z"
    }
   },
   "cell_type": "code",
   "source": "annot = load_pickle('Data/preprocess/video_data/-YwZOeyAQC8_15.mp4/annotations')",
   "id": "544f458414b15a9e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T17:17:52.430923Z",
     "start_time": "2024-09-13T17:17:52.400353Z"
    }
   },
   "cell_type": "code",
   "source": "annot",
   "id": "ee170e071eff78fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      labels           gazes  frame_numbers  left  right  top  bottom  \\\n",
       "0      head1  head1, neither              1     0     94  101     228   \n",
       "1      head2  head2, object1              1    86    155  211     286   \n",
       "2    object1             NaN              1   189    243  279     327   \n",
       "3      head1  head1, neither              2     0     93  101     225   \n",
       "4      head2  head2, object1              2    86    154  211     285   \n",
       "..       ...             ...            ...   ...    ...  ...     ...   \n",
       "255    head2  head2, neither             89    81    149  204     276   \n",
       "256  object1             NaN             89   151    246  257     314   \n",
       "257    head1  head1, neither             90     4     84   98     220   \n",
       "258    head2  head2, neither             90    79    147  205     277   \n",
       "259  object1             NaN             90   154    249  274     331   \n",
       "\n",
       "                                              features  \n",
       "0    [6.680127143859863, 3.3551645278930664, -3.418...  \n",
       "1    [14.151459693908691, 2.1622977256774902, 6.103...  \n",
       "2    [19.33083724975586, -5.286369800567627, -12.16...  \n",
       "3    [6.7137017250061035, 2.192903757095337, -6.567...  \n",
       "4    [15.673377990722656, 2.015958786010742, 4.1520...  \n",
       "..                                                 ...  \n",
       "255  [20.822486877441406, 6.350839138031006, 5.5030...  \n",
       "256  [20.562641143798828, -0.4833153784275055, -10....  \n",
       "257  [13.18536376953125, 0.4746054410934448, -11.00...  \n",
       "258  [20.570606231689453, 6.350813388824463, 5.0889...  \n",
       "259  [20.580768585205078, -0.7884887456893921, -15....  \n",
       "\n",
       "[260 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>gazes</th>\n",
       "      <th>frame_numbers</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>top</th>\n",
       "      <th>bottom</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>head1</td>\n",
       "      <td>head1, neither</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>101</td>\n",
       "      <td>228</td>\n",
       "      <td>[6.680127143859863, 3.3551645278930664, -3.418...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>head2</td>\n",
       "      <td>head2, object1</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>155</td>\n",
       "      <td>211</td>\n",
       "      <td>286</td>\n",
       "      <td>[14.151459693908691, 2.1622977256774902, 6.103...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>object1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>243</td>\n",
       "      <td>279</td>\n",
       "      <td>327</td>\n",
       "      <td>[19.33083724975586, -5.286369800567627, -12.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>head1</td>\n",
       "      <td>head1, neither</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>101</td>\n",
       "      <td>225</td>\n",
       "      <td>[6.7137017250061035, 2.192903757095337, -6.567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>head2</td>\n",
       "      <td>head2, object1</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>154</td>\n",
       "      <td>211</td>\n",
       "      <td>285</td>\n",
       "      <td>[15.673377990722656, 2.015958786010742, 4.1520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>head2</td>\n",
       "      <td>head2, neither</td>\n",
       "      <td>89</td>\n",
       "      <td>81</td>\n",
       "      <td>149</td>\n",
       "      <td>204</td>\n",
       "      <td>276</td>\n",
       "      <td>[20.822486877441406, 6.350839138031006, 5.5030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>object1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89</td>\n",
       "      <td>151</td>\n",
       "      <td>246</td>\n",
       "      <td>257</td>\n",
       "      <td>314</td>\n",
       "      <td>[20.562641143798828, -0.4833153784275055, -10....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>head1</td>\n",
       "      <td>head1, neither</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>98</td>\n",
       "      <td>220</td>\n",
       "      <td>[13.18536376953125, 0.4746054410934448, -11.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>head2</td>\n",
       "      <td>head2, neither</td>\n",
       "      <td>90</td>\n",
       "      <td>79</td>\n",
       "      <td>147</td>\n",
       "      <td>205</td>\n",
       "      <td>277</td>\n",
       "      <td>[20.570606231689453, 6.350813388824463, 5.0889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>object1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>154</td>\n",
       "      <td>249</td>\n",
       "      <td>274</td>\n",
       "      <td>331</td>\n",
       "      <td>[20.580768585205078, -0.7884887456893921, -15....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T17:35:06.326827Z",
     "start_time": "2024-09-13T17:35:03.026288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "video_dir = 'Data/preprocess/video_data'\n",
    "not_valid_videos ={}\n",
    "for video_name in os.listdir(video_dir):\n",
    "    video_path = os.path.join(video_dir, video_name)\n",
    "    annot = load_pickle(os.path.join(video_path, 'annotations'))\n",
    "    grouped = annot.groupby('frame_numbers')\n",
    "    for frame_number, group in grouped:\n",
    "        \n",
    "        if (group['labels'] == 'head1').any() and (group['labels'] == 'head2').any():\n",
    "            continue\n",
    "        else:\n",
    "            if video_name not in not_valid_videos:\n",
    "                not_valid_videos[video_name] = [frame_number]\n",
    "            else:\n",
    "                not_valid_videos[video_name].append(frame_number)"
   ],
   "id": "a61e2a6e9fac76d3",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T17:35:08.661671Z",
     "start_time": "2024-09-13T17:35:08.630408Z"
    }
   },
   "cell_type": "code",
   "source": "len(not_valid_videos)",
   "id": "adbfec8afd166a65",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T17:35:49.909888Z",
     "start_time": "2024-09-13T17:35:49.894281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key, value in not_valid_videos.items():\n",
    "    print(key, value)"
   ],
   "id": "9bbd6718c49f2e93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-YwZOeyAQC8_15.mp4 [58, 59, 60, 61, 70, 71, 72, 73, 86, 87]\n",
      "b7y36KyAIoI_120.mp4 [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "FJzKgF-nR0E_15.mp4 [59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]\n",
      "flickr-4-1-6-2-6-0-0-0-23041626000_1.mp4 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "flickr-4-1-7-8-1-9-6-2-3941781962_7.mp4 [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "flickr-4-7-1-4-7-6-4-0-2447147640_28.mp4 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "flickr-4-8-3-9-9-3-0-9-6748399309_20.mp4 [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "flickr-7-3-3-1-0-7-1-8-2773310718_8.mp4 [86, 87, 88, 89, 90]\n",
      "flickr-7-4-1-1-3-9-5-4-8274113954_15.mp4 [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "flickr-7-7-0-5-0-7-0-9-4177050709_33.mp4 [59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "flickr-8-3-1-6897055831_10.mp4 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "flickr-8-9-7-9-5-0-4-1-6189795041_19.mp4 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "giphy-10TNZYlPEDFR3a_3.mp4 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "vine-MKEjBiBY6Fw_1.mp4 [15, 16, 17, 18, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "vine-MVvgr5hA3JD_1.mp4 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
      "WJ-84ioZqcc_41.mp4 [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "yt--Sv97d457Uw_137.mp4 [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "yt-6RiK4Sg2tSY_75.mp4 [52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]\n",
      "yt-7Gw5igJ3Uc0_45.mp4 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "yt-7we4oftPEXo_245.mp4 [47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "yt-BJa2Fs1UyZ0_71.mp4 [65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "yt-F0Ede8UiICQ_38.mp4 [83, 84, 85, 86, 87, 88, 89, 90]\n",
      "yt-fBN0EWsZbnk_14.mp4 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "yt-gknOwYMSbPs_2.mp4 [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "yt-iRPNwUaA-5w_236.mp4 [76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86]\n",
      "yt-ix0bg7Lgyas_26.mp4 [67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "yt-l8je0Vm72u4_988.mp4 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "yt-m2cwo-pEgDY_25.mp4 [83, 84, 85, 86, 87, 88, 89, 90]\n",
      "yt-o0tfI02ehDE_1.mp4 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "yt-U87RJqCZT8w_16.mp4 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 41, 42, 43, 44, 45, 46, 47, 82, 83, 84, 85, 86, 87]\n",
      "yt-UPu938CNhYc_35.mp4 [1, 2, 3, 4, 5, 6, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80]\n",
      "yt-VmGqoK-hmHc_47.mp4 [79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "yt-xnqqB-leeaQ_128.mp4 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n",
      "yt-yQK3lr5cpSU_37.mp4 [86, 87, 88, 89, 90]\n",
      "yt-zcz5nb7m-Y4_55.mp4 [65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "18c508844e1fa7c3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
